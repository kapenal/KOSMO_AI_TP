{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13ba14b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì¥ë¥´ ê°€ì¤‘ì¹˜ ì ìš©í•˜ì—¬ í•™ìŠµ ë° ì €ì¥ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "# 7ì›” 16ì¼ 13:16 í•™ìŠµ + ì¥ë¥´ ê°€ì¤‘ì¹˜ ì ìš©\n",
    "import json\n",
    "from konlpy.tag import Okt\n",
    "from gensim.models import Word2Vec\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "# ê²½ë¡œ ì„¤ì •\n",
    "DB_PATH = \"C:/kosmo/data/\"\n",
    "PATH = \"C:/kosmo/test_data/IH/\"\n",
    "file_name = \"movies_DB_partial.json\"\n",
    "\n",
    "# ì˜í™” ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "with open(DB_PATH + file_name, encoding=\"utf-8\") as f:\n",
    "    movies = json.load(f)\n",
    "\n",
    "# í˜•íƒœì†Œ ë¶„ì„ê¸°\n",
    "okt = Okt()\n",
    "\n",
    "# ì œëª© + ì¤„ê±°ë¦¬ + ì¥ë¥´ í† í° ì¶”ì¶œ í•¨ìˆ˜ (ì¥ë¥´ ê°€ì¤‘ì¹˜ ë°˜ì˜)\n",
    "def get_tokens(title, overview, genres, genre_weight=3):\n",
    "    title = title or \"\"\n",
    "    overview = overview or \"\"\n",
    "    genres = genres or []\n",
    "\n",
    "    tokens = []\n",
    "\n",
    "    # ì œëª© í† í°\n",
    "    for word, pos in okt.pos(title, stem=True, norm=True):\n",
    "        if pos in ['Noun', 'Verb', 'Adjective']:\n",
    "            tokens.append(word)\n",
    "\n",
    "    # ì¤„ê±°ë¦¬ í† í°\n",
    "    for word, pos in okt.pos(overview, stem=True, norm=True):\n",
    "        if pos in ['Noun', 'Verb', 'Adjective']:\n",
    "            tokens.append(word)\n",
    "\n",
    "    # ì¥ë¥´ í† í° (ê°€ì¤‘ì¹˜ ë¶€ì—¬)\n",
    "    tokens.extend(genres * genre_weight)\n",
    "\n",
    "    return tokens\n",
    "\n",
    "# ì „ì²´ ì˜í™”ì— ëŒ€í•´ í† í°í™”\n",
    "keyword = []\n",
    "for movie in movies:\n",
    "    tokens = get_tokens(movie.get('title_ko'), movie.get('overview'), movie.get('genres'), genre_weight=3)\n",
    "    keyword.append(tokens)\n",
    "\n",
    "# Word2Vec í•™ìŠµ\n",
    "model = Word2Vec(\n",
    "    keyword,\n",
    "    vector_size=100,\n",
    "    window=5,\n",
    "    min_count=1,  # ë“±ì¥ ë¹ˆë„ 1 ì´ìƒ ë‹¨ì–´ í¬í•¨\n",
    "    workers=4,\n",
    "    sg=0  # CBOW ë°©ì‹\n",
    ")\n",
    "\n",
    "# ì œëª© í† í°í™” (ê²€ìƒ‰ìš©, overview/genreëŠ” ì œì™¸)\n",
    "title_tokens = [\n",
    "    get_tokens(movie.get('title_ko'), \"\", [], genre_weight=3)\n",
    "    for movie in movies\n",
    "]\n",
    "\n",
    "joblib.dump(title_tokens, PATH + \"title_tokens.pkl\")\n",
    "\n",
    "# ì˜í™” ë²¡í„° ìƒì„± í•¨ìˆ˜ (í† í° í‰ê· )\n",
    "def get_movie_vector(tokens, model):\n",
    "    vectors = [model.wv[token] for token in tokens if token in model.wv]\n",
    "    return np.mean(np.array(vectors), axis=0) if vectors else np.zeros(model.vector_size)\n",
    "\n",
    "# ì˜í™” ë²¡í„° ê³„ì‚°\n",
    "movie_vectors = [get_movie_vector(tokens, model) for tokens in keyword]\n",
    "\n",
    "# ëª¨ë¸ ë° ë°ì´í„° ì €ì¥\n",
    "joblib.dump(model, PATH + \"word2vec_movie.model\")\n",
    "joblib.dump(movie_vectors, PATH + \"movie_vectors.pkl\")\n",
    "joblib.dump(movies, PATH + \"movies.pkl\")\n",
    "joblib.dump(keyword, PATH + \"keyword.pkl\")\n",
    "\n",
    "print(\"âœ… ì¥ë¥´ ê°€ì¤‘ì¹˜ ì ìš©í•˜ì—¬ í•™ìŠµ ë° ì €ì¥ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b7b3bf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì…ë ¥í•˜ì‹  'ì¸ ì…‰ ì…˜'ê³¼(ì™€) ê°€ì¥ ë¹„ìŠ·í•œ ì˜í™”ëŠ” 'ì¸ì…‰ì…˜'ì…ë‹ˆë‹¤.\n",
      "\n",
      "âœ… 'ì¸ ì…‰ ì…˜' ì¶”ì²œ ì˜í™” ë¦¬ìŠ¤íŠ¸:\n",
      "ğŸ¬ ì—ë°˜ê²Œë¦¬ì˜¨: Q (ê°œë´‰ì¼: 2012-11-17, í‰ì : 7.2)\n",
      "í¬ìŠ¤í„°: https://image.tmdb.org/t/p/w500/zERMhjBDiYoaHGDRsKP6IxzuV5F.jpg\n",
      "ìœ ì‚¬ë„: 0.948\n",
      "\n",
      "ğŸ¬ ìŠ¤ì›Œë“œí”¼ì‰¬ (ê°œë´‰ì¼: 2001-06-08, í‰ì : 6.3)\n",
      "í¬ìŠ¤í„°: https://image.tmdb.org/t/p/w500/63YY0GuORn1G73SAIADVDATdF5A.jpg\n",
      "ìœ ì‚¬ë„: 0.947\n",
      "\n",
      "ğŸ¬ ì„œë³µ (ê°œë´‰ì¼: 2021-04-12, í‰ì : 7.2)\n",
      "í¬ìŠ¤í„°: https://image.tmdb.org/t/p/w500/6R3eKsdVS7ZWrY28QUt3DCG3N72.jpg\n",
      "ìœ ì‚¬ë„: 0.944\n",
      "\n",
      "ğŸ¬ íŒŒì´í”„ë¼ì¸ (ê°œë´‰ì¼: 2021-05-26, í‰ì : 7.0)\n",
      "í¬ìŠ¤í„°: https://image.tmdb.org/t/p/w500/oo4sBEhrOovS1l1qcPo0i1RRacP.jpg\n",
      "ìœ ì‚¬ë„: 0.943\n",
      "\n",
      "ğŸ¬ ë‘ë‡Œìœ í¬í”„ë¡œì íŠ¸, í¼ì¦ (ê°œë´‰ì¼: 2006-09-14, í‰ì : 5.2)\n",
      "í¬ìŠ¤í„°: https://image.tmdb.org/t/p/w500/ts7LKneqQ9MCOwCxd0e1SzQxtX2.jpg\n",
      "ìœ ì‚¬ë„: 0.942\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "import joblib\n",
    "from soynlp.tokenizer import LTokenizer  # soynlpì˜ ë‹¨ìˆœ í† í¬ë‚˜ì´ì € ì‚¬ìš© (ê³µë°± ê¸°ì¤€)\n",
    "\n",
    "# --- íŒŒì¼ ê²½ë¡œ ì„¤ì • ---\n",
    "PATH = \"C:/kosmo/model/\"  # ëª¨ë¸ ë° ë°ì´í„° ì €ì¥ ê²½ë¡œ\n",
    "\n",
    "# --- ëª¨ë¸ ë° ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° ---\n",
    "model = joblib.load(PATH + \"word2vec_movie.model\")        # í•™ìŠµëœ Word2Vec ëª¨ë¸\n",
    "movie_vectors = np.array(joblib.load(PATH + \"movie_vectors.pkl\"))  # ì˜í™”ë³„ ë²¡í„° (ì¤„ê±°ë¦¬+ì¥ë¥´ ê¸°ë°˜)\n",
    "movies = joblib.load(PATH + \"movies.pkl\")                 # ì˜í™” ì •ë³´ ë¦¬ìŠ¤íŠ¸ (ì œëª©, ì¤„ê±°ë¦¬, ì¥ë¥´ ë“±)\n",
    "title_tokens = joblib.load(PATH + \"title_tokens.pkl\")     # ì˜í™” ì œëª©ì„ í† í°í™”í•œ ë¦¬ìŠ¤íŠ¸ (ê²€ìƒ‰ìš©)\n",
    "\n",
    "# --- ì œëª© ê²€ìƒ‰ìš© í† í¬ë‚˜ì´ì € ì¤€ë¹„ (ê³µë°± ê¸°ì¤€ LTokenizer ì‚¬ìš©) ---\n",
    "tokenizer = LTokenizer()\n",
    "\n",
    "def tokenize_title(text):\n",
    "    \"\"\"ì…ë ¥ ì œëª©ì—ì„œ ë¶ˆí•„ìš”í•œ ê³µë°± ì œê±° í›„ í† í°í™”\"\"\"\n",
    "    if not text:\n",
    "        return []\n",
    "    text = text.strip().replace(\" \", \"\")  # â† ê³µë°± ì œê±°\n",
    "    return tokenizer.tokenize(text)\n",
    "\n",
    "def jaccard_similarity(set1, set2):\n",
    "    \"\"\"ë‘ ì§‘í•© ê°„ ìì¹´ë“œ ìœ ì‚¬ë„ ê³„ì‚°\"\"\"\n",
    "    if not set1 or not set2:\n",
    "        return 0.0\n",
    "    return len(set1 & set2) / len(set1 | set2)\n",
    "\n",
    "def find_similar_movie(input_title, title_tokens, threshold=0.1):\n",
    "    \"\"\"\n",
    "    ì…ë ¥í•œ ì œëª©ê³¼ ê°€ì¥ ìœ ì‚¬í•œ ì œëª©ì„ ê°€ì§„ ì˜í™”ì˜ ì¸ë±ìŠ¤ë¥¼ ë°˜í™˜.\n",
    "    - ìœ ì‚¬ë„ëŠ” ìì¹´ë“œ ìœ ì‚¬ë„ ê¸°ë°˜\n",
    "    - ìœ ì‚¬ë„ê°€ threshold ë¯¸ë§Œì´ë©´ -1 ë°˜í™˜\n",
    "    \"\"\"\n",
    "    input_tokens = set(tokenize_title(input_title))\n",
    "    best_match_idx = -1\n",
    "    best_score = 0.0\n",
    "    for idx, tokens in enumerate(title_tokens):\n",
    "        score = jaccard_similarity(input_tokens, set(tokens))\n",
    "        if score > best_score and score >= threshold:\n",
    "            best_score = score\n",
    "            best_match_idx = idx\n",
    "    return best_match_idx\n",
    "\n",
    "def recommend_movie(input_title, movies, movie_vectors, title_tokens, top_n=5):\n",
    "    \"\"\"\n",
    "    ì…ë ¥í•œ ì œëª©ê³¼ ìœ ì‚¬í•œ ì˜í™” 1ê°œë¥¼ ì°¾ì€ í›„,\n",
    "    ê·¸ ì˜í™”ì˜ ë²¡í„°(ì¥ë¥´+ì¤„ê±°ë¦¬)ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ê°€ì¥ ìœ ì‚¬í•œ ì˜í™” top_nê°œë¥¼ ì¶”ì²œ\n",
    "    \"\"\"\n",
    "    matched_idx = find_similar_movie(input_title, title_tokens)\n",
    "\n",
    "    # ìœ ì‚¬í•œ ì œëª©ì„ ì°¾ì§€ ëª»í–ˆì„ ê²½ìš°: ëª¨ë“  ì˜í™” ë²¡í„°ì˜ í‰ê· ì„ ì‚¬ìš©\n",
    "    if matched_idx == -1:\n",
    "        print(f\"'{input_title}'ê³¼(ì™€) ë¹„ìŠ·í•œ ì˜í™”ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì „ì²´ í‰ê·  ë²¡í„°ë¡œ ì¶”ì²œí•©ë‹ˆë‹¤.\")\n",
    "        input_vec = np.mean(movie_vectors, axis=0)\n",
    "    else:\n",
    "        print(f\"ì…ë ¥í•˜ì‹  '{input_title}'ê³¼(ì™€) ê°€ì¥ ë¹„ìŠ·í•œ ì˜í™”ëŠ” '{movies[matched_idx]['title_ko']}'ì…ë‹ˆë‹¤.\")\n",
    "        input_vec = movie_vectors[matched_idx]\n",
    "\n",
    "    # --- ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚° ---\n",
    "    input_norm = np.linalg.norm(input_vec)\n",
    "    vectors_norm = np.linalg.norm(movie_vectors, axis=1)\n",
    "    dot_products = movie_vectors @ input_vec  # ë‚´ì \n",
    "\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        cosine_similarities = dot_products / (vectors_norm * input_norm)  # ìœ ì‚¬ë„ ê³„ì‚°\n",
    "        cosine_similarities = np.nan_to_num(cosine_similarities)  # NaN ë°©ì§€\n",
    "\n",
    "    # ìê¸° ìì‹ ì€ ì œì™¸ (ì¤‘ë³µ ì¶”ì²œ ë°©ì§€)\n",
    "    if matched_idx >= 0:\n",
    "        cosine_similarities[matched_idx] = -1\n",
    "\n",
    "    # ìƒìœ„ top_n ìœ ì‚¬í•œ ì˜í™” ì¸ë±ìŠ¤ ì„ íƒ\n",
    "    top_indices = np.argpartition(-cosine_similarities, top_n)[:top_n]\n",
    "    top_indices = top_indices[np.argsort(-cosine_similarities[top_indices])]  # ìœ ì‚¬ë„ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬\n",
    "\n",
    "    # ì¶”ì²œ ì˜í™” ì •ë³´ êµ¬ì„±\n",
    "    recommendations = []\n",
    "    for i in top_indices:\n",
    "        m = movies[i]\n",
    "        recommendations.append({\n",
    "            \"title_ko\": m.get('title_ko', ''),\n",
    "            \"release_date\": m.get('release_date', ''),\n",
    "            \"vote_average\": m.get('vote_average', 0),\n",
    "            \"poster_path\": m.get('poster_path', ''),\n",
    "            \"similarity\": cosine_similarities[i]\n",
    "        })\n",
    "\n",
    "    return recommendations\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # ì˜ˆì‹œ: ì‚¬ìš©ì ì…ë ¥ ì˜í™” ì œëª©\n",
    "    input_title = \"ì¸ ì…‰ ì…˜\"  # â† ì›í•˜ëŠ” ì œëª©ìœ¼ë¡œ ë³€ê²½ ê°€ëŠ¥\n",
    "\n",
    "    # ì¶”ì²œ ì‹¤í–‰\n",
    "    recs = recommend_movie(input_title, movies, movie_vectors, title_tokens, top_n=5)\n",
    "\n",
    "    # ì¶”ì²œ ê²°ê³¼ ì¶œë ¥\n",
    "    print(f\"\\nâœ… '{input_title}' ì¶”ì²œ ì˜í™” ë¦¬ìŠ¤íŠ¸:\")\n",
    "    for rec in recs:\n",
    "        print(f\"ğŸ¬ {rec['title_ko']} (ê°œë´‰ì¼: {rec['release_date']}, í‰ì : {rec['vote_average']:.1f})\")\n",
    "        print(f\"í¬ìŠ¤í„°: {rec['poster_path']}\")\n",
    "        print(f\"ìœ ì‚¬ë„: {rec['similarity']:.3f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9418070c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"link\": \"/title/36143\",\n",
      "    \"title\": \"ë“œë˜ê³¤\",\n",
      "    \"genres\": \"ì˜í™” Â· 1993\",\n",
      "    \"img\": \"https://file.kinolights.com/m/content_poster/202307/12/32da1bc5-af11-424c-8e49-3d576872de4d.webp\"\n",
      "  },\n",
      "  {\n",
      "    \"link\": \"/title/142067\",\n",
      "    \"title\": \"ë“œë˜ê³¤\",\n",
      "    \"genres\": \"ì˜í™” Â· 2025\",\n",
      "    \"img\": \"https://file.kinolights.com/m/content_poster/202503/24/a338d596-5be5-411b-9fc6-e153f50f1c0b.webp\"\n",
      "  },\n",
      "  {\n",
      "    \"link\": \"/title/36141\",\n",
      "    \"title\": \"ë“œë˜ê³¤\",\n",
      "    \"genres\": \"ì˜í™” Â· 1999\",\n",
      "    \"img\": \"https://file.kinolights.com/m/content_poster/202307/12/810c71c6-46cd-4972-b744-4fafc2a99c45.webp\"\n",
      "  },\n",
      "  {\n",
      "    \"link\": \"/title/104571\",\n",
      "    \"title\": \"ë“œë˜ê³¤ í—¤ë“œ\",\n",
      "    \"genres\": \"ì˜í™” Â· 2003\",\n",
      "    \"img\": \"https://file.kinolights.com/m/content_poster/202307/12/22947f2d-590c-400a-a5f9-d919f8fdbbb1.webp\"\n",
      "  },\n",
      "  {\n",
      "    \"link\": \"/title/3369\",\n",
      "    \"title\": \"ë“œë˜ê³¤ ì›Œ\",\n",
      "    \"genres\": \"ì˜í™” Â· 2017\",\n",
      "    \"img\": \"https://file.kinolights.com/m/content_poster/202307/12/2f8d7609-665c-4e35-be03-1d68273f1287.webp\"\n",
      "  },\n",
      "  {\n",
      "    \"link\": \"/title/96741\",\n",
      "    \"title\": \"ë“œë˜ê³¤ë³¼\",\n",
      "    \"genres\": \"ì• ë‹ˆë©”ì´ì…˜ Â· 1986\",\n",
      "    \"img\": \"https://file.kinolights.com/m/content_poster/202307/12/3668f3ae-ff74-4725-8479-b5bea00d0bf0.webp\"\n",
      "  },\n",
      "  {\n",
      "    \"link\": \"/title/61810\",\n",
      "    \"title\": \"ë“œë˜ê³¤ë³¼\",\n",
      "    \"genres\": \"ì˜í™” Â· 1990\",\n",
      "    \"img\": \"https://file.kinolights.com/m/content_poster/202307/12/0cd96d6e-ed23-4272-b0ac-31534cf972bf.webp\"\n",
      "  },\n",
      "  {\n",
      "    \"link\": \"/title/41665\",\n",
      "    \"title\": \"ë“œë˜ê³¤ í„\",\n",
      "    \"genres\": \"ì˜í™” Â· 2011\",\n",
      "    \"img\": \"https://file.kinolights.com/m/content_poster/202307/12/f99fe9ef-6816-46a9-891c-ce0be675ebf4.webp\"\n",
      "  },\n",
      "  {\n",
      "    \"link\": \"/title/46941\",\n",
      "    \"title\": \"ë ˆë“œ ë“œë˜ê³¤\",\n",
      "    \"genres\": \"ì˜í™” Â· 2002\",\n",
      "    \"img\": \"https://file.kinolights.com/m/content_poster/202307/12/701dfbc4-6bb0-476a-9ed5-0b871483fcd9.webp\"\n",
      "  },\n",
      "  {\n",
      "    \"link\": \"/title/40116\",\n",
      "    \"title\": \"ë ˆë“œ ë“œë˜ê³¤\",\n",
      "    \"genres\": \"ì˜í™” Â· 1999\",\n",
      "    \"img\": \"https://file.kinolights.com/m/content_poster/202307/12/b06b1395-5782-44c2-81ee-88eaebf0a08d.webp\"\n",
      "  },\n",
      "  {\n",
      "    \"link\": \"/title/46194\",\n",
      "    \"title\": \"ë“œë˜ê³¤í•˜íŠ¸\",\n",
      "    \"genres\": \"ì˜í™” Â· 1996\",\n",
      "    \"img\": \"https://file.kinolights.com/m/content_poster/202307/12/279f3155-8685-4982-a56a-2839adc98b70.webp\"\n",
      "  },\n",
      "  {\n",
      "    \"link\": \"/title/39709\",\n",
      "    \"title\": \"ë“œë˜ê³¤ íˆ¬ì¹´\",\n",
      "    \"genres\": \"ì˜í™” Â· 1996\",\n",
      "    \"img\": \"https://file.kinolights.com/m/content_poster/202307/12/afc5c5f3-0e56-4bd4-b682-1990ebc8e293.webp\"\n",
      "  },\n",
      "  {\n",
      "    \"link\": \"/title/104320\",\n",
      "    \"title\": \"ë“œë˜ê³¤ì—ê·¸\",\n",
      "    \"genres\": \"ì• ë‹ˆë©”ì´ì…˜ Â· 2017\",\n",
      "    \"img\": \"https://file.kinolights.com/m/content_poster/202307/12/70f7416f-a026-4efc-b3f1-66ec56f4b6da.webp\"\n",
      "  },\n",
      "  {\n",
      "    \"link\": \"/title/46423\",\n",
      "    \"title\": \"ë”ë¸” ë“œë˜ê³¤\",\n",
      "    \"genres\": \"ì˜í™” Â· 1998\",\n",
      "    \"img\": \"https://file.kinolights.com/m/content_poster/202307/12/7c47b5cd-0f3f-4112-b502-16f3e41c0bbb.webp\"\n",
      "  },\n",
      "  {\n",
      "    \"link\": \"/title/37434\",\n",
      "    \"title\": \"ë“œë˜ê³¤ í—Œí„°\",\n",
      "    \"genres\": \"ì• ë‹ˆë©”ì´ì…˜, ì˜í™” Â· 2013\",\n",
      "    \"img\": \"https://file.kinolights.com/m/content_poster/202307/12/fb7572ff-b818-433a-9e17-f1ad05d20040.webp\"\n",
      "  },\n",
      "  {\n",
      "    \"link\": \"/title/26053\",\n",
      "    \"title\": \"ë“œë˜ê³¤ ìŠ¤í†°\",\n",
      "    \"genres\": \"ì˜í™” Â· 2004\",\n",
      "    \"img\": \"https://file.kinolights.com/m/content_poster/202307/12/b4242950-58c8-48b0-a64d-123d39731933.webp\"\n",
      "  },\n",
      "  {\n",
      "    \"link\": \"/title/94153\",\n",
      "    \"title\": \"ë“œë˜ê³¤ ë¸”ë™\",\n",
      "    \"genres\": \"ì˜í™” Â· 2015\",\n",
      "    \"img\": \"https://file.kinolights.com/m/content_poster/202307/17/9c0c3187-0e35-445f-8b60-6870d72c0f35.webp\"\n",
      "  },\n",
      "  {\n",
      "    \"link\": \"/title/124499\",\n",
      "    \"title\": \"ë“œë˜ê³¤ ë ˆì´ìŠ¤\",\n",
      "    \"genres\": \"ë“œë¼ë§ˆ Â· 2017\",\n",
      "    \"img\": \"https://file.kinolights.com/m/content_poster/202307/12/f0efae5c-f01a-470b-954a-204915973032.webp\"\n",
      "  },\n",
      "  {\n",
      "    \"link\": \"/title/38456\",\n",
      "    \"title\": \"ê·¸ë¦° ë“œë˜ê³¤\",\n",
      "    \"genres\": \"ì˜í™” Â· 2001\",\n",
      "    \"img\": \"https://file.kinolights.com/m/content_poster/202307/12/ffa27af1-475d-4d5d-9361-04a4ab9394d7.webp\"\n",
      "  },\n",
      "  {\n",
      "    \"link\": \"/title/92451\",\n",
      "    \"title\": \"ë“œë˜ê³¤ë³¼ GT\",\n",
      "    \"genres\": \"ì• ë‹ˆë©”ì´ì…˜ Â· 1996\",\n",
      "    \"img\": \"https://file.kinolights.com/m/content_poster/202307/12/25418f1a-57b5-46ac-81ab-0f34223f070c.webp\"\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "from urllib.parse import quote\n",
    "import json\n",
    "\n",
    "search_text = \"ë“œë˜ê³¤\"\n",
    "encoded_text = quote(search_text)\n",
    "url = f\"https://m.kinolights.com/search?keyword={encoded_text}\"\n",
    "\n",
    "# User-Agent ì„¤ì • (ë¸Œë¼ìš°ì €ì²˜ëŸ¼ ìœ„ì¥)\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0 Safari/537.36'\n",
    "}\n",
    "\n",
    "# Request ê°ì²´ ìƒì„±\n",
    "req = urllib.request.Request(url, headers=headers)\n",
    "\n",
    "# HTML ìš”ì²­ ë° íŒŒì‹±\n",
    "res = urllib.request.urlopen(req)\n",
    "soup = BeautifulSoup(res, \"html.parser\")\n",
    "\n",
    "# idê°€ searchContentListì¸ div ì°¾ê¸°\n",
    "search_div = soup.find(\"div\", id=\"searchContentList\")\n",
    "\n",
    "if search_div:\n",
    "    movies = []\n",
    "    a_tags = search_div.find_all(\"a\")  # ëª¨ë“  a íƒœê·¸\n",
    "    for a in a_tags:\n",
    "        href = a.get('href')\n",
    "        title_tag = a.select_one('.metadata__title')\n",
    "        genres_tag = a.select_one('.metadata__subtitle')\n",
    "        img = a.select_one('img')['src'] if a.select_one('img') else ''\n",
    "        title = title_tag.get_text(strip=True) if title_tag else ''\n",
    "        genres = genres_tag.get_text(strip=True) if genres_tag else ''\n",
    "        \n",
    "        movies.append({\n",
    "            \"link\": href,\n",
    "            \"title\": title,\n",
    "            \"genres\": genres,\n",
    "            \"img\": img\n",
    "        })\n",
    "    \n",
    "    # JSON ë¬¸ìì—´ ì¶œë ¥\n",
    "    json_result = json.dumps(movies, ensure_ascii=False, indent=2)\n",
    "    print(json_result)\n",
    "else:\n",
    "    print(\"searchContentList ì˜ì—­ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
