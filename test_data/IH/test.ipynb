{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13ba14b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì¥ë¥´ ê°€ì¤‘ì¹˜ ì ìš©í•˜ì—¬ í•™ìŠµ ë° ì €ì¥ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "# 7ì›” 16ì¼ 13:16 í•™ìŠµ + ì¥ë¥´ ê°€ì¤‘ì¹˜ ì ìš©\n",
    "import json\n",
    "from konlpy.tag import Okt\n",
    "from gensim.models import Word2Vec\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "# ê²½ë¡œ ì„¤ì •\n",
    "DB_PATH = \"C:/kosmo/data/\"\n",
    "PATH = \"C:/kosmo/test_data/IH/\"\n",
    "file_name = \"movies_DB_partial.json\"\n",
    "\n",
    "# ì˜í™” ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "with open(DB_PATH + file_name, encoding=\"utf-8\") as f:\n",
    "    movies = json.load(f)\n",
    "\n",
    "# í˜•íƒœì†Œ ë¶„ì„ê¸°\n",
    "okt = Okt()\n",
    "\n",
    "# ì œëª© + ì¤„ê±°ë¦¬ + ì¥ë¥´ í† í° ì¶”ì¶œ í•¨ìˆ˜ (ì¥ë¥´ ê°€ì¤‘ì¹˜ ë°˜ì˜)\n",
    "def get_tokens(title, overview, genres, genre_weight=3):\n",
    "    title = title or \"\"\n",
    "    overview = overview or \"\"\n",
    "    genres = genres or []\n",
    "\n",
    "    tokens = []\n",
    "\n",
    "    # ì œëª© í† í°\n",
    "    for word, pos in okt.pos(title, stem=True, norm=True):\n",
    "        if pos in ['Noun', 'Verb', 'Adjective']:\n",
    "            tokens.append(word)\n",
    "\n",
    "    # ì¤„ê±°ë¦¬ í† í°\n",
    "    for word, pos in okt.pos(overview, stem=True, norm=True):\n",
    "        if pos in ['Noun', 'Verb', 'Adjective']:\n",
    "            tokens.append(word)\n",
    "\n",
    "    # ì¥ë¥´ í† í° (ê°€ì¤‘ì¹˜ ë¶€ì—¬)\n",
    "    tokens.extend(genres * genre_weight)\n",
    "\n",
    "    return tokens\n",
    "\n",
    "# ì „ì²´ ì˜í™”ì— ëŒ€í•´ í† í°í™”\n",
    "keyword = []\n",
    "for movie in movies:\n",
    "    tokens = get_tokens(movie.get('title_ko'), movie.get('overview'), movie.get('genres'), genre_weight=3)\n",
    "    keyword.append(tokens)\n",
    "\n",
    "# Word2Vec í•™ìŠµ\n",
    "model = Word2Vec(\n",
    "    keyword,\n",
    "    vector_size=100,\n",
    "    window=5,\n",
    "    min_count=1,  # ë“±ì¥ ë¹ˆë„ 1 ì´ìƒ ë‹¨ì–´ í¬í•¨\n",
    "    workers=4,\n",
    "    sg=0  # CBOW ë°©ì‹\n",
    ")\n",
    "\n",
    "# ì œëª© í† í°í™” (ê²€ìƒ‰ìš©, overview/genreëŠ” ì œì™¸)\n",
    "title_tokens = [\n",
    "    get_tokens(movie.get('title_ko'), \"\", [], genre_weight=3)\n",
    "    for movie in movies\n",
    "]\n",
    "\n",
    "joblib.dump(title_tokens, PATH + \"title_tokens.pkl\")\n",
    "\n",
    "# ì˜í™” ë²¡í„° ìƒì„± í•¨ìˆ˜ (í† í° í‰ê· )\n",
    "def get_movie_vector(tokens, model):\n",
    "    vectors = [model.wv[token] for token in tokens if token in model.wv]\n",
    "    return np.mean(np.array(vectors), axis=0) if vectors else np.zeros(model.vector_size)\n",
    "\n",
    "# ì˜í™” ë²¡í„° ê³„ì‚°\n",
    "movie_vectors = [get_movie_vector(tokens, model) for tokens in keyword]\n",
    "\n",
    "# ëª¨ë¸ ë° ë°ì´í„° ì €ì¥\n",
    "joblib.dump(model, PATH + \"word2vec_movie.model\")\n",
    "joblib.dump(movie_vectors, PATH + \"movie_vectors.pkl\")\n",
    "joblib.dump(movies, PATH + \"movies.pkl\")\n",
    "joblib.dump(keyword, PATH + \"keyword.pkl\")\n",
    "\n",
    "print(\"âœ… ì¥ë¥´ ê°€ì¤‘ì¹˜ ì ìš©í•˜ì—¬ í•™ìŠµ ë° ì €ì¥ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b7b3bf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì…ë ¥í•˜ì‹  'ì¸ ì…‰ ì…˜'ê³¼(ì™€) ê°€ì¥ ë¹„ìŠ·í•œ ì˜í™”ëŠ” 'ì¸ì…‰ì…˜'ì…ë‹ˆë‹¤.\n",
      "\n",
      "âœ… 'ì¸ ì…‰ ì…˜' ì¶”ì²œ ì˜í™” ë¦¬ìŠ¤íŠ¸:\n",
      "ğŸ¬ ì—ë°˜ê²Œë¦¬ì˜¨: Q (ê°œë´‰ì¼: 2012-11-17, í‰ì : 7.2)\n",
      "í¬ìŠ¤í„°: https://image.tmdb.org/t/p/w500/zERMhjBDiYoaHGDRsKP6IxzuV5F.jpg\n",
      "ìœ ì‚¬ë„: 0.948\n",
      "\n",
      "ğŸ¬ ìŠ¤ì›Œë“œí”¼ì‰¬ (ê°œë´‰ì¼: 2001-06-08, í‰ì : 6.3)\n",
      "í¬ìŠ¤í„°: https://image.tmdb.org/t/p/w500/63YY0GuORn1G73SAIADVDATdF5A.jpg\n",
      "ìœ ì‚¬ë„: 0.947\n",
      "\n",
      "ğŸ¬ ì„œë³µ (ê°œë´‰ì¼: 2021-04-12, í‰ì : 7.2)\n",
      "í¬ìŠ¤í„°: https://image.tmdb.org/t/p/w500/6R3eKsdVS7ZWrY28QUt3DCG3N72.jpg\n",
      "ìœ ì‚¬ë„: 0.944\n",
      "\n",
      "ğŸ¬ íŒŒì´í”„ë¼ì¸ (ê°œë´‰ì¼: 2021-05-26, í‰ì : 7.0)\n",
      "í¬ìŠ¤í„°: https://image.tmdb.org/t/p/w500/oo4sBEhrOovS1l1qcPo0i1RRacP.jpg\n",
      "ìœ ì‚¬ë„: 0.943\n",
      "\n",
      "ğŸ¬ ë‘ë‡Œìœ í¬í”„ë¡œì íŠ¸, í¼ì¦ (ê°œë´‰ì¼: 2006-09-14, í‰ì : 5.2)\n",
      "í¬ìŠ¤í„°: https://image.tmdb.org/t/p/w500/ts7LKneqQ9MCOwCxd0e1SzQxtX2.jpg\n",
      "ìœ ì‚¬ë„: 0.942\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "import joblib\n",
    "from soynlp.tokenizer import LTokenizer  # soynlpì˜ ë‹¨ìˆœ í† í¬ë‚˜ì´ì € ì‚¬ìš© (ê³µë°± ê¸°ì¤€)\n",
    "\n",
    "# --- íŒŒì¼ ê²½ë¡œ ì„¤ì • ---\n",
    "PATH = \"C:/kosmo/model/\"  # ëª¨ë¸ ë° ë°ì´í„° ì €ì¥ ê²½ë¡œ\n",
    "\n",
    "# --- ëª¨ë¸ ë° ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° ---\n",
    "model = joblib.load(PATH + \"word2vec_movie.model\")        # í•™ìŠµëœ Word2Vec ëª¨ë¸\n",
    "movie_vectors = np.array(joblib.load(PATH + \"movie_vectors.pkl\"))  # ì˜í™”ë³„ ë²¡í„° (ì¤„ê±°ë¦¬+ì¥ë¥´ ê¸°ë°˜)\n",
    "movies = joblib.load(PATH + \"movies.pkl\")                 # ì˜í™” ì •ë³´ ë¦¬ìŠ¤íŠ¸ (ì œëª©, ì¤„ê±°ë¦¬, ì¥ë¥´ ë“±)\n",
    "title_tokens = joblib.load(PATH + \"title_tokens.pkl\")     # ì˜í™” ì œëª©ì„ í† í°í™”í•œ ë¦¬ìŠ¤íŠ¸ (ê²€ìƒ‰ìš©)\n",
    "\n",
    "# --- ì œëª© ê²€ìƒ‰ìš© í† í¬ë‚˜ì´ì € ì¤€ë¹„ (ê³µë°± ê¸°ì¤€ LTokenizer ì‚¬ìš©) ---\n",
    "tokenizer = LTokenizer()\n",
    "\n",
    "def tokenize_title(text):\n",
    "    \"\"\"ì…ë ¥ ì œëª©ì—ì„œ ë¶ˆí•„ìš”í•œ ê³µë°± ì œê±° í›„ í† í°í™”\"\"\"\n",
    "    if not text:\n",
    "        return []\n",
    "    text = text.strip().replace(\" \", \"\")  # â† ê³µë°± ì œê±°\n",
    "    return tokenizer.tokenize(text)\n",
    "\n",
    "def jaccard_similarity(set1, set2):\n",
    "    \"\"\"ë‘ ì§‘í•© ê°„ ìì¹´ë“œ ìœ ì‚¬ë„ ê³„ì‚°\"\"\"\n",
    "    if not set1 or not set2:\n",
    "        return 0.0\n",
    "    return len(set1 & set2) / len(set1 | set2)\n",
    "\n",
    "def find_similar_movie(input_title, title_tokens, threshold=0.1):\n",
    "    \"\"\"\n",
    "    ì…ë ¥í•œ ì œëª©ê³¼ ê°€ì¥ ìœ ì‚¬í•œ ì œëª©ì„ ê°€ì§„ ì˜í™”ì˜ ì¸ë±ìŠ¤ë¥¼ ë°˜í™˜.\n",
    "    - ìœ ì‚¬ë„ëŠ” ìì¹´ë“œ ìœ ì‚¬ë„ ê¸°ë°˜\n",
    "    - ìœ ì‚¬ë„ê°€ threshold ë¯¸ë§Œì´ë©´ -1 ë°˜í™˜\n",
    "    \"\"\"\n",
    "    input_tokens = set(tokenize_title(input_title))\n",
    "    best_match_idx = -1\n",
    "    best_score = 0.0\n",
    "    for idx, tokens in enumerate(title_tokens):\n",
    "        score = jaccard_similarity(input_tokens, set(tokens))\n",
    "        if score > best_score and score >= threshold:\n",
    "            best_score = score\n",
    "            best_match_idx = idx\n",
    "    return best_match_idx\n",
    "\n",
    "def recommend_movie(input_title, movies, movie_vectors, title_tokens, top_n=5):\n",
    "    \"\"\"\n",
    "    ì…ë ¥í•œ ì œëª©ê³¼ ìœ ì‚¬í•œ ì˜í™” 1ê°œë¥¼ ì°¾ì€ í›„,\n",
    "    ê·¸ ì˜í™”ì˜ ë²¡í„°(ì¥ë¥´+ì¤„ê±°ë¦¬)ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ê°€ì¥ ìœ ì‚¬í•œ ì˜í™” top_nê°œë¥¼ ì¶”ì²œ\n",
    "    \"\"\"\n",
    "    matched_idx = find_similar_movie(input_title, title_tokens)\n",
    "\n",
    "    # ìœ ì‚¬í•œ ì œëª©ì„ ì°¾ì§€ ëª»í–ˆì„ ê²½ìš°: ëª¨ë“  ì˜í™” ë²¡í„°ì˜ í‰ê· ì„ ì‚¬ìš©\n",
    "    if matched_idx == -1:\n",
    "        print(f\"'{input_title}'ê³¼(ì™€) ë¹„ìŠ·í•œ ì˜í™”ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì „ì²´ í‰ê·  ë²¡í„°ë¡œ ì¶”ì²œí•©ë‹ˆë‹¤.\")\n",
    "        input_vec = np.mean(movie_vectors, axis=0)\n",
    "    else:\n",
    "        print(f\"ì…ë ¥í•˜ì‹  '{input_title}'ê³¼(ì™€) ê°€ì¥ ë¹„ìŠ·í•œ ì˜í™”ëŠ” '{movies[matched_idx]['title_ko']}'ì…ë‹ˆë‹¤.\")\n",
    "        input_vec = movie_vectors[matched_idx]\n",
    "\n",
    "    # --- ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚° ---\n",
    "    input_norm = np.linalg.norm(input_vec)\n",
    "    vectors_norm = np.linalg.norm(movie_vectors, axis=1)\n",
    "    dot_products = movie_vectors @ input_vec  # ë‚´ì \n",
    "\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        cosine_similarities = dot_products / (vectors_norm * input_norm)  # ìœ ì‚¬ë„ ê³„ì‚°\n",
    "        cosine_similarities = np.nan_to_num(cosine_similarities)  # NaN ë°©ì§€\n",
    "\n",
    "    # ìê¸° ìì‹ ì€ ì œì™¸ (ì¤‘ë³µ ì¶”ì²œ ë°©ì§€)\n",
    "    if matched_idx >= 0:\n",
    "        cosine_similarities[matched_idx] = -1\n",
    "\n",
    "    # ìƒìœ„ top_n ìœ ì‚¬í•œ ì˜í™” ì¸ë±ìŠ¤ ì„ íƒ\n",
    "    top_indices = np.argpartition(-cosine_similarities, top_n)[:top_n]\n",
    "    top_indices = top_indices[np.argsort(-cosine_similarities[top_indices])]  # ìœ ì‚¬ë„ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬\n",
    "\n",
    "    # ì¶”ì²œ ì˜í™” ì •ë³´ êµ¬ì„±\n",
    "    recommendations = []\n",
    "    for i in top_indices:\n",
    "        m = movies[i]\n",
    "        recommendations.append({\n",
    "            \"title_ko\": m.get('title_ko', ''),\n",
    "            \"release_date\": m.get('release_date', ''),\n",
    "            \"vote_average\": m.get('vote_average', 0),\n",
    "            \"poster_path\": m.get('poster_path', ''),\n",
    "            \"similarity\": cosine_similarities[i]\n",
    "        })\n",
    "\n",
    "    return recommendations\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # ì˜ˆì‹œ: ì‚¬ìš©ì ì…ë ¥ ì˜í™” ì œëª©\n",
    "    input_title = \"ì¸ ì…‰ ì…˜\"  # â† ì›í•˜ëŠ” ì œëª©ìœ¼ë¡œ ë³€ê²½ ê°€ëŠ¥\n",
    "\n",
    "    # ì¶”ì²œ ì‹¤í–‰\n",
    "    recs = recommend_movie(input_title, movies, movie_vectors, title_tokens, top_n=5)\n",
    "\n",
    "    # ì¶”ì²œ ê²°ê³¼ ì¶œë ¥\n",
    "    print(f\"\\nâœ… '{input_title}' ì¶”ì²œ ì˜í™” ë¦¬ìŠ¤íŠ¸:\")\n",
    "    for rec in recs:\n",
    "        print(f\"ğŸ¬ {rec['title_ko']} (ê°œë´‰ì¼: {rec['release_date']}, í‰ì : {rec['vote_average']:.1f})\")\n",
    "        print(f\"í¬ìŠ¤í„°: {rec['poster_path']}\")\n",
    "        print(f\"ìœ ì‚¬ë„: {rec['similarity']:.3f}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
